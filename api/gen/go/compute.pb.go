// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v3.19.6
// source: compute.proto

package computev1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// GenerateRequest with routing annotations
type GenerateRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required: The prompt text
	Prompt string `protobuf:"bytes,1,opt,name=prompt,proto3" json:"prompt,omitempty"`
	// Optional: Specific model to use (e.g., "llama3:7b")
	Model string `protobuf:"bytes,2,opt,name=model,proto3" json:"model,omitempty"`
	// Routing Annotations
	Annotations *JobAnnotations `protobuf:"bytes,3,opt,name=annotations,proto3" json:"annotations,omitempty"`
	// Generation options
	Options       *GenerationOptions `protobuf:"bytes,4,opt,name=options,proto3" json:"options,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GenerateRequest) Reset() {
	*x = GenerateRequest{}
	mi := &file_compute_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GenerateRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GenerateRequest) ProtoMessage() {}

func (x *GenerateRequest) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GenerateRequest.ProtoReflect.Descriptor instead.
func (*GenerateRequest) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{0}
}

func (x *GenerateRequest) GetPrompt() string {
	if x != nil {
		return x.Prompt
	}
	return ""
}

func (x *GenerateRequest) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *GenerateRequest) GetAnnotations() *JobAnnotations {
	if x != nil {
		return x.Annotations
	}
	return nil
}

func (x *GenerateRequest) GetOptions() *GenerationOptions {
	if x != nil {
		return x.Options
	}
	return nil
}

// JobAnnotations control routing behavior
type JobAnnotations struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Hardware target preference
	// Values: "npu", "igpu", "nvidia", "cpu", "auto", "openai"
	Target string `protobuf:"bytes,1,opt,name=target,proto3" json:"target,omitempty"`
	// Latency requirement
	LatencyCritical bool `protobuf:"varint,2,opt,name=latency_critical,json=latencyCritical,proto3" json:"latency_critical,omitempty"`
	// Power efficiency preference (useful for battery operation)
	PreferPowerEfficiency bool `protobuf:"varint,3,opt,name=prefer_power_efficiency,json=preferPowerEfficiency,proto3" json:"prefer_power_efficiency,omitempty"`
	// Enable response caching
	CacheEnabled bool `protobuf:"varint,4,opt,name=cache_enabled,json=cacheEnabled,proto3" json:"cache_enabled,omitempty"`
	// Maximum acceptable latency in milliseconds
	MaxLatencyMs int32 `protobuf:"varint,5,opt,name=max_latency_ms,json=maxLatencyMs,proto3" json:"max_latency_ms,omitempty"`
	// Maximum power budget in watts
	MaxPowerWatts int32 `protobuf:"varint,6,opt,name=max_power_watts,json=maxPowerWatts,proto3" json:"max_power_watts,omitempty"`
	// Additional custom annotations
	Custom        map[string]string `protobuf:"bytes,7,rep,name=custom,proto3" json:"custom,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *JobAnnotations) Reset() {
	*x = JobAnnotations{}
	mi := &file_compute_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *JobAnnotations) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*JobAnnotations) ProtoMessage() {}

func (x *JobAnnotations) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use JobAnnotations.ProtoReflect.Descriptor instead.
func (*JobAnnotations) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{1}
}

func (x *JobAnnotations) GetTarget() string {
	if x != nil {
		return x.Target
	}
	return ""
}

func (x *JobAnnotations) GetLatencyCritical() bool {
	if x != nil {
		return x.LatencyCritical
	}
	return false
}

func (x *JobAnnotations) GetPreferPowerEfficiency() bool {
	if x != nil {
		return x.PreferPowerEfficiency
	}
	return false
}

func (x *JobAnnotations) GetCacheEnabled() bool {
	if x != nil {
		return x.CacheEnabled
	}
	return false
}

func (x *JobAnnotations) GetMaxLatencyMs() int32 {
	if x != nil {
		return x.MaxLatencyMs
	}
	return 0
}

func (x *JobAnnotations) GetMaxPowerWatts() int32 {
	if x != nil {
		return x.MaxPowerWatts
	}
	return 0
}

func (x *JobAnnotations) GetCustom() map[string]string {
	if x != nil {
		return x.Custom
	}
	return nil
}

// GenerationOptions for inference
type GenerationOptions struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Maximum tokens to generate
	MaxTokens int32 `protobuf:"varint,1,opt,name=max_tokens,json=maxTokens,proto3" json:"max_tokens,omitempty"`
	// Temperature (0.0 to 2.0)
	Temperature float32 `protobuf:"fixed32,2,opt,name=temperature,proto3" json:"temperature,omitempty"`
	// Top-p sampling
	TopP float32 `protobuf:"fixed32,3,opt,name=top_p,json=topP,proto3" json:"top_p,omitempty"`
	// Top-k sampling
	TopK int32 `protobuf:"varint,4,opt,name=top_k,json=topK,proto3" json:"top_k,omitempty"`
	// Stop sequences
	Stop []string `protobuf:"bytes,5,rep,name=stop,proto3" json:"stop,omitempty"`
	// Context length
	ContextLength int32 `protobuf:"varint,6,opt,name=context_length,json=contextLength,proto3" json:"context_length,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GenerationOptions) Reset() {
	*x = GenerationOptions{}
	mi := &file_compute_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GenerationOptions) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GenerationOptions) ProtoMessage() {}

func (x *GenerationOptions) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GenerationOptions.ProtoReflect.Descriptor instead.
func (*GenerationOptions) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{2}
}

func (x *GenerationOptions) GetMaxTokens() int32 {
	if x != nil {
		return x.MaxTokens
	}
	return 0
}

func (x *GenerationOptions) GetTemperature() float32 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

func (x *GenerationOptions) GetTopP() float32 {
	if x != nil {
		return x.TopP
	}
	return 0
}

func (x *GenerationOptions) GetTopK() int32 {
	if x != nil {
		return x.TopK
	}
	return 0
}

func (x *GenerationOptions) GetStop() []string {
	if x != nil {
		return x.Stop
	}
	return nil
}

func (x *GenerationOptions) GetContextLength() int32 {
	if x != nil {
		return x.ContextLength
	}
	return 0
}

// GenerateResponse
type GenerateResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Generated text
	Response string `protobuf:"bytes,1,opt,name=response,proto3" json:"response,omitempty"`
	// Backend that processed the request
	BackendUsed string `protobuf:"bytes,2,opt,name=backend_used,json=backendUsed,proto3" json:"backend_used,omitempty"`
	// Routing metadata
	Routing *RoutingMetadata `protobuf:"bytes,3,opt,name=routing,proto3" json:"routing,omitempty"`
	// Generation statistics
	Stats *GenerationStats `protobuf:"bytes,4,opt,name=stats,proto3" json:"stats,omitempty"`
	// Whether response came from cache
	FromCache     bool `protobuf:"varint,5,opt,name=from_cache,json=fromCache,proto3" json:"from_cache,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GenerateResponse) Reset() {
	*x = GenerateResponse{}
	mi := &file_compute_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GenerateResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GenerateResponse) ProtoMessage() {}

func (x *GenerateResponse) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GenerateResponse.ProtoReflect.Descriptor instead.
func (*GenerateResponse) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{3}
}

func (x *GenerateResponse) GetResponse() string {
	if x != nil {
		return x.Response
	}
	return ""
}

func (x *GenerateResponse) GetBackendUsed() string {
	if x != nil {
		return x.BackendUsed
	}
	return ""
}

func (x *GenerateResponse) GetRouting() *RoutingMetadata {
	if x != nil {
		return x.Routing
	}
	return nil
}

func (x *GenerateResponse) GetStats() *GenerationStats {
	if x != nil {
		return x.Stats
	}
	return nil
}

func (x *GenerateResponse) GetFromCache() bool {
	if x != nil {
		return x.FromCache
	}
	return false
}

// GenerateStreamResponse for streaming
type GenerateStreamResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Token or chunk of text
	Token string `protobuf:"bytes,1,opt,name=token,proto3" json:"token,omitempty"`
	// Whether this is the final message
	Done bool `protobuf:"varint,2,opt,name=done,proto3" json:"done,omitempty"`
	// Backend used (sent in first message)
	BackendUsed string `protobuf:"bytes,3,opt,name=backend_used,json=backendUsed,proto3" json:"backend_used,omitempty"`
	// Stats (sent in final message)
	Stats         *GenerationStats `protobuf:"bytes,4,opt,name=stats,proto3" json:"stats,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GenerateStreamResponse) Reset() {
	*x = GenerateStreamResponse{}
	mi := &file_compute_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GenerateStreamResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GenerateStreamResponse) ProtoMessage() {}

func (x *GenerateStreamResponse) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GenerateStreamResponse.ProtoReflect.Descriptor instead.
func (*GenerateStreamResponse) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{4}
}

func (x *GenerateStreamResponse) GetToken() string {
	if x != nil {
		return x.Token
	}
	return ""
}

func (x *GenerateStreamResponse) GetDone() bool {
	if x != nil {
		return x.Done
	}
	return false
}

func (x *GenerateStreamResponse) GetBackendUsed() string {
	if x != nil {
		return x.BackendUsed
	}
	return ""
}

func (x *GenerateStreamResponse) GetStats() *GenerationStats {
	if x != nil {
		return x.Stats
	}
	return nil
}

// RoutingMetadata explains routing decision
type RoutingMetadata struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Selected backend
	Backend string `protobuf:"bytes,1,opt,name=backend,proto3" json:"backend,omitempty"`
	// Reason for selection
	Reason string `protobuf:"bytes,2,opt,name=reason,proto3" json:"reason,omitempty"`
	// Estimated power consumption (watts)
	EstimatedPowerWatts float32 `protobuf:"fixed32,3,opt,name=estimated_power_watts,json=estimatedPowerWatts,proto3" json:"estimated_power_watts,omitempty"`
	// Estimated latency (milliseconds)
	EstimatedLatencyMs int32 `protobuf:"varint,4,opt,name=estimated_latency_ms,json=estimatedLatencyMs,proto3" json:"estimated_latency_ms,omitempty"`
	// Alternative backends that could have handled this
	Alternatives  []string `protobuf:"bytes,5,rep,name=alternatives,proto3" json:"alternatives,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RoutingMetadata) Reset() {
	*x = RoutingMetadata{}
	mi := &file_compute_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RoutingMetadata) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RoutingMetadata) ProtoMessage() {}

func (x *RoutingMetadata) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RoutingMetadata.ProtoReflect.Descriptor instead.
func (*RoutingMetadata) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{5}
}

func (x *RoutingMetadata) GetBackend() string {
	if x != nil {
		return x.Backend
	}
	return ""
}

func (x *RoutingMetadata) GetReason() string {
	if x != nil {
		return x.Reason
	}
	return ""
}

func (x *RoutingMetadata) GetEstimatedPowerWatts() float32 {
	if x != nil {
		return x.EstimatedPowerWatts
	}
	return 0
}

func (x *RoutingMetadata) GetEstimatedLatencyMs() int32 {
	if x != nil {
		return x.EstimatedLatencyMs
	}
	return 0
}

func (x *RoutingMetadata) GetAlternatives() []string {
	if x != nil {
		return x.Alternatives
	}
	return nil
}

// GenerationStats
type GenerationStats struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Time to first token (ms)
	TimeToFirstTokenMs int32 `protobuf:"varint,1,opt,name=time_to_first_token_ms,json=timeToFirstTokenMs,proto3" json:"time_to_first_token_ms,omitempty"`
	// Total generation time (ms)
	TotalTimeMs int32 `protobuf:"varint,2,opt,name=total_time_ms,json=totalTimeMs,proto3" json:"total_time_ms,omitempty"`
	// Tokens generated
	TokensGenerated int32 `protobuf:"varint,3,opt,name=tokens_generated,json=tokensGenerated,proto3" json:"tokens_generated,omitempty"`
	// Tokens per second
	TokensPerSecond float32 `protobuf:"fixed32,4,opt,name=tokens_per_second,json=tokensPerSecond,proto3" json:"tokens_per_second,omitempty"`
	// Energy consumed (watt-hours)
	EnergyWh      float32 `protobuf:"fixed32,5,opt,name=energy_wh,json=energyWh,proto3" json:"energy_wh,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GenerationStats) Reset() {
	*x = GenerationStats{}
	mi := &file_compute_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GenerationStats) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GenerationStats) ProtoMessage() {}

func (x *GenerationStats) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GenerationStats.ProtoReflect.Descriptor instead.
func (*GenerationStats) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{6}
}

func (x *GenerationStats) GetTimeToFirstTokenMs() int32 {
	if x != nil {
		return x.TimeToFirstTokenMs
	}
	return 0
}

func (x *GenerationStats) GetTotalTimeMs() int32 {
	if x != nil {
		return x.TotalTimeMs
	}
	return 0
}

func (x *GenerationStats) GetTokensGenerated() int32 {
	if x != nil {
		return x.TokensGenerated
	}
	return 0
}

func (x *GenerationStats) GetTokensPerSecond() float32 {
	if x != nil {
		return x.TokensPerSecond
	}
	return 0
}

func (x *GenerationStats) GetEnergyWh() float32 {
	if x != nil {
		return x.EnergyWh
	}
	return 0
}

// EmbedRequest
type EmbedRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Text to embed
	Text string `protobuf:"bytes,1,opt,name=text,proto3" json:"text,omitempty"`
	// Model for embeddings
	Model string `protobuf:"bytes,2,opt,name=model,proto3" json:"model,omitempty"`
	// Routing annotations
	Annotations   *JobAnnotations `protobuf:"bytes,3,opt,name=annotations,proto3" json:"annotations,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *EmbedRequest) Reset() {
	*x = EmbedRequest{}
	mi := &file_compute_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *EmbedRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*EmbedRequest) ProtoMessage() {}

func (x *EmbedRequest) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use EmbedRequest.ProtoReflect.Descriptor instead.
func (*EmbedRequest) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{7}
}

func (x *EmbedRequest) GetText() string {
	if x != nil {
		return x.Text
	}
	return ""
}

func (x *EmbedRequest) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *EmbedRequest) GetAnnotations() *JobAnnotations {
	if x != nil {
		return x.Annotations
	}
	return nil
}

// EmbedResponse
type EmbedResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Embedding vector
	Embedding []float32 `protobuf:"fixed32,1,rep,packed,name=embedding,proto3" json:"embedding,omitempty"`
	// Backend used
	BackendUsed string `protobuf:"bytes,2,opt,name=backend_used,json=backendUsed,proto3" json:"backend_used,omitempty"`
	// Routing metadata
	Routing       *RoutingMetadata `protobuf:"bytes,3,opt,name=routing,proto3" json:"routing,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *EmbedResponse) Reset() {
	*x = EmbedResponse{}
	mi := &file_compute_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *EmbedResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*EmbedResponse) ProtoMessage() {}

func (x *EmbedResponse) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use EmbedResponse.ProtoReflect.Descriptor instead.
func (*EmbedResponse) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{8}
}

func (x *EmbedResponse) GetEmbedding() []float32 {
	if x != nil {
		return x.Embedding
	}
	return nil
}

func (x *EmbedResponse) GetBackendUsed() string {
	if x != nil {
		return x.BackendUsed
	}
	return ""
}

func (x *EmbedResponse) GetRouting() *RoutingMetadata {
	if x != nil {
		return x.Routing
	}
	return nil
}

// ListBackendsRequest
type ListBackendsRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional: filter by type
	TypeFilter    string `protobuf:"bytes,1,opt,name=type_filter,json=typeFilter,proto3" json:"type_filter,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListBackendsRequest) Reset() {
	*x = ListBackendsRequest{}
	mi := &file_compute_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListBackendsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListBackendsRequest) ProtoMessage() {}

func (x *ListBackendsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListBackendsRequest.ProtoReflect.Descriptor instead.
func (*ListBackendsRequest) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{9}
}

func (x *ListBackendsRequest) GetTypeFilter() string {
	if x != nil {
		return x.TypeFilter
	}
	return ""
}

// ListBackendsResponse
type ListBackendsResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Backends      []*BackendInfo         `protobuf:"bytes,1,rep,name=backends,proto3" json:"backends,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListBackendsResponse) Reset() {
	*x = ListBackendsResponse{}
	mi := &file_compute_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListBackendsResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListBackendsResponse) ProtoMessage() {}

func (x *ListBackendsResponse) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListBackendsResponse.ProtoReflect.Descriptor instead.
func (*ListBackendsResponse) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{10}
}

func (x *ListBackendsResponse) GetBackends() []*BackendInfo {
	if x != nil {
		return x.Backends
	}
	return nil
}

// BackendInfo
type BackendInfo struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Unique identifier
	Id string `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	// Type: "ollama", "openai", "vectordb", etc.
	Type string `protobuf:"bytes,2,opt,name=type,proto3" json:"type,omitempty"`
	// Human-readable name
	Name string `protobuf:"bytes,3,opt,name=name,proto3" json:"name,omitempty"`
	// Hardware: "npu", "igpu", "nvidia", "cpu", "cloud"
	Hardware string `protobuf:"bytes,4,opt,name=hardware,proto3" json:"hardware,omitempty"`
	// Current status
	Status *BackendStatus `protobuf:"bytes,5,opt,name=status,proto3" json:"status,omitempty"`
	// Capabilities
	Capabilities *BackendCapabilities `protobuf:"bytes,6,opt,name=capabilities,proto3" json:"capabilities,omitempty"`
	// Current metrics
	Metrics       *BackendMetrics `protobuf:"bytes,7,opt,name=metrics,proto3" json:"metrics,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BackendInfo) Reset() {
	*x = BackendInfo{}
	mi := &file_compute_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BackendInfo) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BackendInfo) ProtoMessage() {}

func (x *BackendInfo) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BackendInfo.ProtoReflect.Descriptor instead.
func (*BackendInfo) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{11}
}

func (x *BackendInfo) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *BackendInfo) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *BackendInfo) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *BackendInfo) GetHardware() string {
	if x != nil {
		return x.Hardware
	}
	return ""
}

func (x *BackendInfo) GetStatus() *BackendStatus {
	if x != nil {
		return x.Status
	}
	return nil
}

func (x *BackendInfo) GetCapabilities() *BackendCapabilities {
	if x != nil {
		return x.Capabilities
	}
	return nil
}

func (x *BackendInfo) GetMetrics() *BackendMetrics {
	if x != nil {
		return x.Metrics
	}
	return nil
}

// BackendStatus
type BackendStatus struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// healthy, degraded, unhealthy, offline
	State string `protobuf:"bytes,1,opt,name=state,proto3" json:"state,omitempty"`
	// Human-readable status message
	Message string `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	// Last health check timestamp
	LastCheckUnix int64 `protobuf:"varint,3,opt,name=last_check_unix,json=lastCheckUnix,proto3" json:"last_check_unix,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BackendStatus) Reset() {
	*x = BackendStatus{}
	mi := &file_compute_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BackendStatus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BackendStatus) ProtoMessage() {}

func (x *BackendStatus) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BackendStatus.ProtoReflect.Descriptor instead.
func (*BackendStatus) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{12}
}

func (x *BackendStatus) GetState() string {
	if x != nil {
		return x.State
	}
	return ""
}

func (x *BackendStatus) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

func (x *BackendStatus) GetLastCheckUnix() int64 {
	if x != nil {
		return x.LastCheckUnix
	}
	return 0
}

// BackendCapabilities
type BackendCapabilities struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Supports text generation
	Generate bool `protobuf:"varint,1,opt,name=generate,proto3" json:"generate,omitempty"`
	// Supports embeddings
	Embed bool `protobuf:"varint,2,opt,name=embed,proto3" json:"embed,omitempty"`
	// Supports streaming
	Stream bool `protobuf:"varint,3,opt,name=stream,proto3" json:"stream,omitempty"`
	// Available models
	Models []string `protobuf:"bytes,4,rep,name=models,proto3" json:"models,omitempty"`
	// Maximum context length
	MaxContext    int32 `protobuf:"varint,5,opt,name=max_context,json=maxContext,proto3" json:"max_context,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BackendCapabilities) Reset() {
	*x = BackendCapabilities{}
	mi := &file_compute_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BackendCapabilities) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BackendCapabilities) ProtoMessage() {}

func (x *BackendCapabilities) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BackendCapabilities.ProtoReflect.Descriptor instead.
func (*BackendCapabilities) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{13}
}

func (x *BackendCapabilities) GetGenerate() bool {
	if x != nil {
		return x.Generate
	}
	return false
}

func (x *BackendCapabilities) GetEmbed() bool {
	if x != nil {
		return x.Embed
	}
	return false
}

func (x *BackendCapabilities) GetStream() bool {
	if x != nil {
		return x.Stream
	}
	return false
}

func (x *BackendCapabilities) GetModels() []string {
	if x != nil {
		return x.Models
	}
	return nil
}

func (x *BackendCapabilities) GetMaxContext() int32 {
	if x != nil {
		return x.MaxContext
	}
	return 0
}

// BackendMetrics
type BackendMetrics struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Average latency (ms)
	AvgLatencyMs int32 `protobuf:"varint,1,opt,name=avg_latency_ms,json=avgLatencyMs,proto3" json:"avg_latency_ms,omitempty"`
	// Requests per minute
	RequestsPerMinute int32 `protobuf:"varint,2,opt,name=requests_per_minute,json=requestsPerMinute,proto3" json:"requests_per_minute,omitempty"`
	// Error rate (0.0 to 1.0)
	ErrorRate float32 `protobuf:"fixed32,3,opt,name=error_rate,json=errorRate,proto3" json:"error_rate,omitempty"`
	// Current power draw (watts)
	PowerWatts float32 `protobuf:"fixed32,4,opt,name=power_watts,json=powerWatts,proto3" json:"power_watts,omitempty"`
	// Models currently loaded in memory
	LoadedModels  []string `protobuf:"bytes,5,rep,name=loaded_models,json=loadedModels,proto3" json:"loaded_models,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BackendMetrics) Reset() {
	*x = BackendMetrics{}
	mi := &file_compute_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BackendMetrics) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BackendMetrics) ProtoMessage() {}

func (x *BackendMetrics) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BackendMetrics.ProtoReflect.Descriptor instead.
func (*BackendMetrics) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{14}
}

func (x *BackendMetrics) GetAvgLatencyMs() int32 {
	if x != nil {
		return x.AvgLatencyMs
	}
	return 0
}

func (x *BackendMetrics) GetRequestsPerMinute() int32 {
	if x != nil {
		return x.RequestsPerMinute
	}
	return 0
}

func (x *BackendMetrics) GetErrorRate() float32 {
	if x != nil {
		return x.ErrorRate
	}
	return 0
}

func (x *BackendMetrics) GetPowerWatts() float32 {
	if x != nil {
		return x.PowerWatts
	}
	return 0
}

func (x *BackendMetrics) GetLoadedModels() []string {
	if x != nil {
		return x.LoadedModels
	}
	return nil
}

// HealthCheckRequest
type HealthCheckRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthCheckRequest) Reset() {
	*x = HealthCheckRequest{}
	mi := &file_compute_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthCheckRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthCheckRequest) ProtoMessage() {}

func (x *HealthCheckRequest) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthCheckRequest.ProtoReflect.Descriptor instead.
func (*HealthCheckRequest) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{15}
}

// HealthCheckResponse
type HealthCheckResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Overall health status
	Status string `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
	// Individual backend health
	BackendHealth map[string]string `protobuf:"bytes,2,rep,name=backend_health,json=backendHealth,proto3" json:"backend_health,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Timestamp
	TimestampUnix int64 `protobuf:"varint,3,opt,name=timestamp_unix,json=timestampUnix,proto3" json:"timestamp_unix,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthCheckResponse) Reset() {
	*x = HealthCheckResponse{}
	mi := &file_compute_proto_msgTypes[16]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthCheckResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthCheckResponse) ProtoMessage() {}

func (x *HealthCheckResponse) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[16]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthCheckResponse.ProtoReflect.Descriptor instead.
func (*HealthCheckResponse) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{16}
}

func (x *HealthCheckResponse) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *HealthCheckResponse) GetBackendHealth() map[string]string {
	if x != nil {
		return x.BackendHealth
	}
	return nil
}

func (x *HealthCheckResponse) GetTimestampUnix() int64 {
	if x != nil {
		return x.TimestampUnix
	}
	return 0
}

// ExecutePipelineRequest
type ExecutePipelineRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Pipeline ID (from config) or inline pipeline definition
	PipelineId string `protobuf:"bytes,1,opt,name=pipeline_id,json=pipelineId,proto3" json:"pipeline_id,omitempty"`
	// Input data (flexible JSON)
	Input map[string]string `protobuf:"bytes,2,rep,name=input,proto3" json:"input,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Override pipeline options
	Options *PipelineOptions `protobuf:"bytes,3,opt,name=options,proto3" json:"options,omitempty"`
	// Annotations for routing
	Annotations   *JobAnnotations `protobuf:"bytes,4,opt,name=annotations,proto3" json:"annotations,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ExecutePipelineRequest) Reset() {
	*x = ExecutePipelineRequest{}
	mi := &file_compute_proto_msgTypes[17]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExecutePipelineRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExecutePipelineRequest) ProtoMessage() {}

func (x *ExecutePipelineRequest) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[17]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ExecutePipelineRequest.ProtoReflect.Descriptor instead.
func (*ExecutePipelineRequest) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{17}
}

func (x *ExecutePipelineRequest) GetPipelineId() string {
	if x != nil {
		return x.PipelineId
	}
	return ""
}

func (x *ExecutePipelineRequest) GetInput() map[string]string {
	if x != nil {
		return x.Input
	}
	return nil
}

func (x *ExecutePipelineRequest) GetOptions() *PipelineOptions {
	if x != nil {
		return x.Options
	}
	return nil
}

func (x *ExecutePipelineRequest) GetAnnotations() *JobAnnotations {
	if x != nil {
		return x.Annotations
	}
	return nil
}

// PipelineOptions
type PipelineOptions struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Enable streaming output
	EnableStreaming bool `protobuf:"varint,1,opt,name=enable_streaming,json=enableStreaming,proto3" json:"enable_streaming,omitempty"`
	// Preserve context between stages
	PreserveContext bool `protobuf:"varint,2,opt,name=preserve_context,json=preserveContext,proto3" json:"preserve_context,omitempty"`
	// Continue on error
	ContinueOnError bool `protobuf:"varint,3,opt,name=continue_on_error,json=continueOnError,proto3" json:"continue_on_error,omitempty"`
	// Collect detailed metrics
	CollectMetrics bool `protobuf:"varint,4,opt,name=collect_metrics,json=collectMetrics,proto3" json:"collect_metrics,omitempty"`
	// Timeout per stage (milliseconds)
	StageTimeoutMs int32 `protobuf:"varint,5,opt,name=stage_timeout_ms,json=stageTimeoutMs,proto3" json:"stage_timeout_ms,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *PipelineOptions) Reset() {
	*x = PipelineOptions{}
	mi := &file_compute_proto_msgTypes[18]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PipelineOptions) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PipelineOptions) ProtoMessage() {}

func (x *PipelineOptions) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[18]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PipelineOptions.ProtoReflect.Descriptor instead.
func (*PipelineOptions) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{18}
}

func (x *PipelineOptions) GetEnableStreaming() bool {
	if x != nil {
		return x.EnableStreaming
	}
	return false
}

func (x *PipelineOptions) GetPreserveContext() bool {
	if x != nil {
		return x.PreserveContext
	}
	return false
}

func (x *PipelineOptions) GetContinueOnError() bool {
	if x != nil {
		return x.ContinueOnError
	}
	return false
}

func (x *PipelineOptions) GetCollectMetrics() bool {
	if x != nil {
		return x.CollectMetrics
	}
	return false
}

func (x *PipelineOptions) GetStageTimeoutMs() int32 {
	if x != nil {
		return x.StageTimeoutMs
	}
	return 0
}

// ExecutePipelineResponse
type ExecutePipelineResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Pipeline ID
	PipelineId string `protobuf:"bytes,1,opt,name=pipeline_id,json=pipelineId,proto3" json:"pipeline_id,omitempty"`
	// Success status
	Success bool `protobuf:"varint,2,opt,name=success,proto3" json:"success,omitempty"`
	// Final output (flexible JSON)
	FinalOutput map[string]string `protobuf:"bytes,3,rep,name=final_output,json=finalOutput,proto3" json:"final_output,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Stage results
	StageResults []*StageResult `protobuf:"bytes,4,rep,name=stage_results,json=stageResults,proto3" json:"stage_results,omitempty"`
	// Total execution time
	TotalTimeMs int32 `protobuf:"varint,5,opt,name=total_time_ms,json=totalTimeMs,proto3" json:"total_time_ms,omitempty"`
	// Total energy consumed
	TotalEnergyWh float32 `protobuf:"fixed32,6,opt,name=total_energy_wh,json=totalEnergyWh,proto3" json:"total_energy_wh,omitempty"`
	// Error message (if failed)
	Error         string `protobuf:"bytes,7,opt,name=error,proto3" json:"error,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ExecutePipelineResponse) Reset() {
	*x = ExecutePipelineResponse{}
	mi := &file_compute_proto_msgTypes[19]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExecutePipelineResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExecutePipelineResponse) ProtoMessage() {}

func (x *ExecutePipelineResponse) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[19]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ExecutePipelineResponse.ProtoReflect.Descriptor instead.
func (*ExecutePipelineResponse) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{19}
}

func (x *ExecutePipelineResponse) GetPipelineId() string {
	if x != nil {
		return x.PipelineId
	}
	return ""
}

func (x *ExecutePipelineResponse) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *ExecutePipelineResponse) GetFinalOutput() map[string]string {
	if x != nil {
		return x.FinalOutput
	}
	return nil
}

func (x *ExecutePipelineResponse) GetStageResults() []*StageResult {
	if x != nil {
		return x.StageResults
	}
	return nil
}

func (x *ExecutePipelineResponse) GetTotalTimeMs() int32 {
	if x != nil {
		return x.TotalTimeMs
	}
	return 0
}

func (x *ExecutePipelineResponse) GetTotalEnergyWh() float32 {
	if x != nil {
		return x.TotalEnergyWh
	}
	return 0
}

func (x *ExecutePipelineResponse) GetError() string {
	if x != nil {
		return x.Error
	}
	return ""
}

// StageResult
type StageResult struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Stage ID
	StageId string `protobuf:"bytes,1,opt,name=stage_id,json=stageId,proto3" json:"stage_id,omitempty"`
	// Backend used
	Backend string `protobuf:"bytes,2,opt,name=backend,proto3" json:"backend,omitempty"`
	// Success status
	Success bool `protobuf:"varint,3,opt,name=success,proto3" json:"success,omitempty"`
	// Stage output (flexible)
	Output string `protobuf:"bytes,4,opt,name=output,proto3" json:"output,omitempty"`
	// Stage metadata
	Metadata *StageMetadata `protobuf:"bytes,5,opt,name=metadata,proto3" json:"metadata,omitempty"`
	// Error message (if failed)
	Error         string `protobuf:"bytes,6,opt,name=error,proto3" json:"error,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StageResult) Reset() {
	*x = StageResult{}
	mi := &file_compute_proto_msgTypes[20]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StageResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StageResult) ProtoMessage() {}

func (x *StageResult) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[20]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StageResult.ProtoReflect.Descriptor instead.
func (*StageResult) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{20}
}

func (x *StageResult) GetStageId() string {
	if x != nil {
		return x.StageId
	}
	return ""
}

func (x *StageResult) GetBackend() string {
	if x != nil {
		return x.Backend
	}
	return ""
}

func (x *StageResult) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *StageResult) GetOutput() string {
	if x != nil {
		return x.Output
	}
	return ""
}

func (x *StageResult) GetMetadata() *StageMetadata {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *StageResult) GetError() string {
	if x != nil {
		return x.Error
	}
	return ""
}

// StageMetadata
type StageMetadata struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Start timestamp
	StartTimeUnix int64 `protobuf:"varint,1,opt,name=start_time_unix,json=startTimeUnix,proto3" json:"start_time_unix,omitempty"`
	// End timestamp
	EndTimeUnix int64 `protobuf:"varint,2,opt,name=end_time_unix,json=endTimeUnix,proto3" json:"end_time_unix,omitempty"`
	// Duration in milliseconds
	DurationMs int64 `protobuf:"varint,3,opt,name=duration_ms,json=durationMs,proto3" json:"duration_ms,omitempty"`
	// Model used
	Model string `protobuf:"bytes,4,opt,name=model,proto3" json:"model,omitempty"`
	// Tokens in
	TokensIn int32 `protobuf:"varint,5,opt,name=tokens_in,json=tokensIn,proto3" json:"tokens_in,omitempty"`
	// Tokens out
	TokensOut int32 `protobuf:"varint,6,opt,name=tokens_out,json=tokensOut,proto3" json:"tokens_out,omitempty"`
	// Confidence score (if applicable)
	Confidence float32 `protobuf:"fixed32,7,opt,name=confidence,proto3" json:"confidence,omitempty"`
	// Temperature
	Temperature float32 `protobuf:"fixed32,8,opt,name=temperature,proto3" json:"temperature,omitempty"`
	// Fan speed
	FanSpeed int32 `protobuf:"varint,9,opt,name=fan_speed,json=fanSpeed,proto3" json:"fan_speed,omitempty"`
	// Whether forwarding occurred
	Forwarded bool `protobuf:"varint,10,opt,name=forwarded,proto3" json:"forwarded,omitempty"`
	// Forwarding reason
	ForwardReason string `protobuf:"bytes,11,opt,name=forward_reason,json=forwardReason,proto3" json:"forward_reason,omitempty"`
	// Attempt count
	AttemptCount  int32 `protobuf:"varint,12,opt,name=attempt_count,json=attemptCount,proto3" json:"attempt_count,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StageMetadata) Reset() {
	*x = StageMetadata{}
	mi := &file_compute_proto_msgTypes[21]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StageMetadata) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StageMetadata) ProtoMessage() {}

func (x *StageMetadata) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[21]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StageMetadata.ProtoReflect.Descriptor instead.
func (*StageMetadata) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{21}
}

func (x *StageMetadata) GetStartTimeUnix() int64 {
	if x != nil {
		return x.StartTimeUnix
	}
	return 0
}

func (x *StageMetadata) GetEndTimeUnix() int64 {
	if x != nil {
		return x.EndTimeUnix
	}
	return 0
}

func (x *StageMetadata) GetDurationMs() int64 {
	if x != nil {
		return x.DurationMs
	}
	return 0
}

func (x *StageMetadata) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *StageMetadata) GetTokensIn() int32 {
	if x != nil {
		return x.TokensIn
	}
	return 0
}

func (x *StageMetadata) GetTokensOut() int32 {
	if x != nil {
		return x.TokensOut
	}
	return 0
}

func (x *StageMetadata) GetConfidence() float32 {
	if x != nil {
		return x.Confidence
	}
	return 0
}

func (x *StageMetadata) GetTemperature() float32 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

func (x *StageMetadata) GetFanSpeed() int32 {
	if x != nil {
		return x.FanSpeed
	}
	return 0
}

func (x *StageMetadata) GetForwarded() bool {
	if x != nil {
		return x.Forwarded
	}
	return false
}

func (x *StageMetadata) GetForwardReason() string {
	if x != nil {
		return x.ForwardReason
	}
	return ""
}

func (x *StageMetadata) GetAttemptCount() int32 {
	if x != nil {
		return x.AttemptCount
	}
	return 0
}

// PipelineStreamResponse
type PipelineStreamResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Stage ID currently executing
	StageId string `protobuf:"bytes,1,opt,name=stage_id,json=stageId,proto3" json:"stage_id,omitempty"`
	// Partial output from current stage
	PartialOutput string `protobuf:"bytes,2,opt,name=partial_output,json=partialOutput,proto3" json:"partial_output,omitempty"`
	// Whether pipeline is complete
	Done bool `protobuf:"varint,3,opt,name=done,proto3" json:"done,omitempty"`
	// Stage result (sent when stage completes)
	StageResult *StageResult `protobuf:"bytes,4,opt,name=stage_result,json=stageResult,proto3" json:"stage_result,omitempty"`
	// Final result (sent when pipeline completes)
	FinalResult   *ExecutePipelineResponse `protobuf:"bytes,5,opt,name=final_result,json=finalResult,proto3" json:"final_result,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PipelineStreamResponse) Reset() {
	*x = PipelineStreamResponse{}
	mi := &file_compute_proto_msgTypes[22]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PipelineStreamResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PipelineStreamResponse) ProtoMessage() {}

func (x *PipelineStreamResponse) ProtoReflect() protoreflect.Message {
	mi := &file_compute_proto_msgTypes[22]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PipelineStreamResponse.ProtoReflect.Descriptor instead.
func (*PipelineStreamResponse) Descriptor() ([]byte, []int) {
	return file_compute_proto_rawDescGZIP(), []int{22}
}

func (x *PipelineStreamResponse) GetStageId() string {
	if x != nil {
		return x.StageId
	}
	return ""
}

func (x *PipelineStreamResponse) GetPartialOutput() string {
	if x != nil {
		return x.PartialOutput
	}
	return ""
}

func (x *PipelineStreamResponse) GetDone() bool {
	if x != nil {
		return x.Done
	}
	return false
}

func (x *PipelineStreamResponse) GetStageResult() *StageResult {
	if x != nil {
		return x.StageResult
	}
	return nil
}

func (x *PipelineStreamResponse) GetFinalResult() *ExecutePipelineResponse {
	if x != nil {
		return x.FinalResult
	}
	return nil
}

var File_compute_proto protoreflect.FileDescriptor

const file_compute_proto_rawDesc = "" +
	"\n" +
	"\rcompute.proto\x12\n" +
	"compute.v1\"\xb6\x01\n" +
	"\x0fGenerateRequest\x12\x16\n" +
	"\x06prompt\x18\x01 \x01(\tR\x06prompt\x12\x14\n" +
	"\x05model\x18\x02 \x01(\tR\x05model\x12<\n" +
	"\vannotations\x18\x03 \x01(\v2\x1a.compute.v1.JobAnnotationsR\vannotations\x127\n" +
	"\aoptions\x18\x04 \x01(\v2\x1d.compute.v1.GenerationOptionsR\aoptions\"\xf9\x02\n" +
	"\x0eJobAnnotations\x12\x16\n" +
	"\x06target\x18\x01 \x01(\tR\x06target\x12)\n" +
	"\x10latency_critical\x18\x02 \x01(\bR\x0flatencyCritical\x126\n" +
	"\x17prefer_power_efficiency\x18\x03 \x01(\bR\x15preferPowerEfficiency\x12#\n" +
	"\rcache_enabled\x18\x04 \x01(\bR\fcacheEnabled\x12$\n" +
	"\x0emax_latency_ms\x18\x05 \x01(\x05R\fmaxLatencyMs\x12&\n" +
	"\x0fmax_power_watts\x18\x06 \x01(\x05R\rmaxPowerWatts\x12>\n" +
	"\x06custom\x18\a \x03(\v2&.compute.v1.JobAnnotations.CustomEntryR\x06custom\x1a9\n" +
	"\vCustomEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xb9\x01\n" +
	"\x11GenerationOptions\x12\x1d\n" +
	"\n" +
	"max_tokens\x18\x01 \x01(\x05R\tmaxTokens\x12 \n" +
	"\vtemperature\x18\x02 \x01(\x02R\vtemperature\x12\x13\n" +
	"\x05top_p\x18\x03 \x01(\x02R\x04topP\x12\x13\n" +
	"\x05top_k\x18\x04 \x01(\x05R\x04topK\x12\x12\n" +
	"\x04stop\x18\x05 \x03(\tR\x04stop\x12%\n" +
	"\x0econtext_length\x18\x06 \x01(\x05R\rcontextLength\"\xda\x01\n" +
	"\x10GenerateResponse\x12\x1a\n" +
	"\bresponse\x18\x01 \x01(\tR\bresponse\x12!\n" +
	"\fbackend_used\x18\x02 \x01(\tR\vbackendUsed\x125\n" +
	"\arouting\x18\x03 \x01(\v2\x1b.compute.v1.RoutingMetadataR\arouting\x121\n" +
	"\x05stats\x18\x04 \x01(\v2\x1b.compute.v1.GenerationStatsR\x05stats\x12\x1d\n" +
	"\n" +
	"from_cache\x18\x05 \x01(\bR\tfromCache\"\x98\x01\n" +
	"\x16GenerateStreamResponse\x12\x14\n" +
	"\x05token\x18\x01 \x01(\tR\x05token\x12\x12\n" +
	"\x04done\x18\x02 \x01(\bR\x04done\x12!\n" +
	"\fbackend_used\x18\x03 \x01(\tR\vbackendUsed\x121\n" +
	"\x05stats\x18\x04 \x01(\v2\x1b.compute.v1.GenerationStatsR\x05stats\"\xcd\x01\n" +
	"\x0fRoutingMetadata\x12\x18\n" +
	"\abackend\x18\x01 \x01(\tR\abackend\x12\x16\n" +
	"\x06reason\x18\x02 \x01(\tR\x06reason\x122\n" +
	"\x15estimated_power_watts\x18\x03 \x01(\x02R\x13estimatedPowerWatts\x120\n" +
	"\x14estimated_latency_ms\x18\x04 \x01(\x05R\x12estimatedLatencyMs\x12\"\n" +
	"\falternatives\x18\x05 \x03(\tR\falternatives\"\xdd\x01\n" +
	"\x0fGenerationStats\x122\n" +
	"\x16time_to_first_token_ms\x18\x01 \x01(\x05R\x12timeToFirstTokenMs\x12\"\n" +
	"\rtotal_time_ms\x18\x02 \x01(\x05R\vtotalTimeMs\x12)\n" +
	"\x10tokens_generated\x18\x03 \x01(\x05R\x0ftokensGenerated\x12*\n" +
	"\x11tokens_per_second\x18\x04 \x01(\x02R\x0ftokensPerSecond\x12\x1b\n" +
	"\tenergy_wh\x18\x05 \x01(\x02R\benergyWh\"v\n" +
	"\fEmbedRequest\x12\x12\n" +
	"\x04text\x18\x01 \x01(\tR\x04text\x12\x14\n" +
	"\x05model\x18\x02 \x01(\tR\x05model\x12<\n" +
	"\vannotations\x18\x03 \x01(\v2\x1a.compute.v1.JobAnnotationsR\vannotations\"\x87\x01\n" +
	"\rEmbedResponse\x12\x1c\n" +
	"\tembedding\x18\x01 \x03(\x02R\tembedding\x12!\n" +
	"\fbackend_used\x18\x02 \x01(\tR\vbackendUsed\x125\n" +
	"\arouting\x18\x03 \x01(\v2\x1b.compute.v1.RoutingMetadataR\arouting\"6\n" +
	"\x13ListBackendsRequest\x12\x1f\n" +
	"\vtype_filter\x18\x01 \x01(\tR\n" +
	"typeFilter\"K\n" +
	"\x14ListBackendsResponse\x123\n" +
	"\bbackends\x18\x01 \x03(\v2\x17.compute.v1.BackendInfoR\bbackends\"\x8f\x02\n" +
	"\vBackendInfo\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12\x12\n" +
	"\x04type\x18\x02 \x01(\tR\x04type\x12\x12\n" +
	"\x04name\x18\x03 \x01(\tR\x04name\x12\x1a\n" +
	"\bhardware\x18\x04 \x01(\tR\bhardware\x121\n" +
	"\x06status\x18\x05 \x01(\v2\x19.compute.v1.BackendStatusR\x06status\x12C\n" +
	"\fcapabilities\x18\x06 \x01(\v2\x1f.compute.v1.BackendCapabilitiesR\fcapabilities\x124\n" +
	"\ametrics\x18\a \x01(\v2\x1a.compute.v1.BackendMetricsR\ametrics\"g\n" +
	"\rBackendStatus\x12\x14\n" +
	"\x05state\x18\x01 \x01(\tR\x05state\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\x12&\n" +
	"\x0flast_check_unix\x18\x03 \x01(\x03R\rlastCheckUnix\"\x98\x01\n" +
	"\x13BackendCapabilities\x12\x1a\n" +
	"\bgenerate\x18\x01 \x01(\bR\bgenerate\x12\x14\n" +
	"\x05embed\x18\x02 \x01(\bR\x05embed\x12\x16\n" +
	"\x06stream\x18\x03 \x01(\bR\x06stream\x12\x16\n" +
	"\x06models\x18\x04 \x03(\tR\x06models\x12\x1f\n" +
	"\vmax_context\x18\x05 \x01(\x05R\n" +
	"maxContext\"\xcb\x01\n" +
	"\x0eBackendMetrics\x12$\n" +
	"\x0eavg_latency_ms\x18\x01 \x01(\x05R\favgLatencyMs\x12.\n" +
	"\x13requests_per_minute\x18\x02 \x01(\x05R\x11requestsPerMinute\x12\x1d\n" +
	"\n" +
	"error_rate\x18\x03 \x01(\x02R\terrorRate\x12\x1f\n" +
	"\vpower_watts\x18\x04 \x01(\x02R\n" +
	"powerWatts\x12#\n" +
	"\rloaded_models\x18\x05 \x03(\tR\floadedModels\"\x14\n" +
	"\x12HealthCheckRequest\"\xf1\x01\n" +
	"\x13HealthCheckResponse\x12\x16\n" +
	"\x06status\x18\x01 \x01(\tR\x06status\x12Y\n" +
	"\x0ebackend_health\x18\x02 \x03(\v22.compute.v1.HealthCheckResponse.BackendHealthEntryR\rbackendHealth\x12%\n" +
	"\x0etimestamp_unix\x18\x03 \x01(\x03R\rtimestampUnix\x1a@\n" +
	"\x12BackendHealthEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xad\x02\n" +
	"\x16ExecutePipelineRequest\x12\x1f\n" +
	"\vpipeline_id\x18\x01 \x01(\tR\n" +
	"pipelineId\x12C\n" +
	"\x05input\x18\x02 \x03(\v2-.compute.v1.ExecutePipelineRequest.InputEntryR\x05input\x125\n" +
	"\aoptions\x18\x03 \x01(\v2\x1b.compute.v1.PipelineOptionsR\aoptions\x12<\n" +
	"\vannotations\x18\x04 \x01(\v2\x1a.compute.v1.JobAnnotationsR\vannotations\x1a8\n" +
	"\n" +
	"InputEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xe6\x01\n" +
	"\x0fPipelineOptions\x12)\n" +
	"\x10enable_streaming\x18\x01 \x01(\bR\x0fenableStreaming\x12)\n" +
	"\x10preserve_context\x18\x02 \x01(\bR\x0fpreserveContext\x12*\n" +
	"\x11continue_on_error\x18\x03 \x01(\bR\x0fcontinueOnError\x12'\n" +
	"\x0fcollect_metrics\x18\x04 \x01(\bR\x0ecollectMetrics\x12(\n" +
	"\x10stage_timeout_ms\x18\x05 \x01(\x05R\x0estageTimeoutMs\"\x8d\x03\n" +
	"\x17ExecutePipelineResponse\x12\x1f\n" +
	"\vpipeline_id\x18\x01 \x01(\tR\n" +
	"pipelineId\x12\x18\n" +
	"\asuccess\x18\x02 \x01(\bR\asuccess\x12W\n" +
	"\ffinal_output\x18\x03 \x03(\v24.compute.v1.ExecutePipelineResponse.FinalOutputEntryR\vfinalOutput\x12<\n" +
	"\rstage_results\x18\x04 \x03(\v2\x17.compute.v1.StageResultR\fstageResults\x12\"\n" +
	"\rtotal_time_ms\x18\x05 \x01(\x05R\vtotalTimeMs\x12&\n" +
	"\x0ftotal_energy_wh\x18\x06 \x01(\x02R\rtotalEnergyWh\x12\x14\n" +
	"\x05error\x18\a \x01(\tR\x05error\x1a>\n" +
	"\x10FinalOutputEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xc1\x01\n" +
	"\vStageResult\x12\x19\n" +
	"\bstage_id\x18\x01 \x01(\tR\astageId\x12\x18\n" +
	"\abackend\x18\x02 \x01(\tR\abackend\x12\x18\n" +
	"\asuccess\x18\x03 \x01(\bR\asuccess\x12\x16\n" +
	"\x06output\x18\x04 \x01(\tR\x06output\x125\n" +
	"\bmetadata\x18\x05 \x01(\v2\x19.compute.v1.StageMetadataR\bmetadata\x12\x14\n" +
	"\x05error\x18\x06 \x01(\tR\x05error\"\x97\x03\n" +
	"\rStageMetadata\x12&\n" +
	"\x0fstart_time_unix\x18\x01 \x01(\x03R\rstartTimeUnix\x12\"\n" +
	"\rend_time_unix\x18\x02 \x01(\x03R\vendTimeUnix\x12\x1f\n" +
	"\vduration_ms\x18\x03 \x01(\x03R\n" +
	"durationMs\x12\x14\n" +
	"\x05model\x18\x04 \x01(\tR\x05model\x12\x1b\n" +
	"\ttokens_in\x18\x05 \x01(\x05R\btokensIn\x12\x1d\n" +
	"\n" +
	"tokens_out\x18\x06 \x01(\x05R\ttokensOut\x12\x1e\n" +
	"\n" +
	"confidence\x18\a \x01(\x02R\n" +
	"confidence\x12 \n" +
	"\vtemperature\x18\b \x01(\x02R\vtemperature\x12\x1b\n" +
	"\tfan_speed\x18\t \x01(\x05R\bfanSpeed\x12\x1c\n" +
	"\tforwarded\x18\n" +
	" \x01(\bR\tforwarded\x12%\n" +
	"\x0eforward_reason\x18\v \x01(\tR\rforwardReason\x12#\n" +
	"\rattempt_count\x18\f \x01(\x05R\fattemptCount\"\xf2\x01\n" +
	"\x16PipelineStreamResponse\x12\x19\n" +
	"\bstage_id\x18\x01 \x01(\tR\astageId\x12%\n" +
	"\x0epartial_output\x18\x02 \x01(\tR\rpartialOutput\x12\x12\n" +
	"\x04done\x18\x03 \x01(\bR\x04done\x12:\n" +
	"\fstage_result\x18\x04 \x01(\v2\x17.compute.v1.StageResultR\vstageResult\x12F\n" +
	"\ffinal_result\x18\x05 \x01(\v2#.compute.v1.ExecutePipelineResponseR\vfinalResult2\xcc\x04\n" +
	"\x0eComputeService\x12E\n" +
	"\bGenerate\x12\x1b.compute.v1.GenerateRequest\x1a\x1c.compute.v1.GenerateResponse\x12S\n" +
	"\x0eGenerateStream\x12\x1b.compute.v1.GenerateRequest\x1a\".compute.v1.GenerateStreamResponse0\x01\x12<\n" +
	"\x05Embed\x12\x18.compute.v1.EmbedRequest\x1a\x19.compute.v1.EmbedResponse\x12Q\n" +
	"\fListBackends\x12\x1f.compute.v1.ListBackendsRequest\x1a .compute.v1.ListBackendsResponse\x12N\n" +
	"\vHealthCheck\x12\x1e.compute.v1.HealthCheckRequest\x1a\x1f.compute.v1.HealthCheckResponse\x12Z\n" +
	"\x0fExecutePipeline\x12\".compute.v1.ExecutePipelineRequest\x1a#.compute.v1.ExecutePipelineResponse\x12a\n" +
	"\x15ExecutePipelineStream\x12\".compute.v1.ExecutePipelineRequest\x1a\".compute.v1.PipelineStreamResponse0\x01BBZ@github.com/daoneill/ollama-proxy/api/gen/go/compute/v1;computev1b\x06proto3"

var (
	file_compute_proto_rawDescOnce sync.Once
	file_compute_proto_rawDescData []byte
)

func file_compute_proto_rawDescGZIP() []byte {
	file_compute_proto_rawDescOnce.Do(func() {
		file_compute_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_compute_proto_rawDesc), len(file_compute_proto_rawDesc)))
	})
	return file_compute_proto_rawDescData
}

var file_compute_proto_msgTypes = make([]protoimpl.MessageInfo, 27)
var file_compute_proto_goTypes = []any{
	(*GenerateRequest)(nil),         // 0: compute.v1.GenerateRequest
	(*JobAnnotations)(nil),          // 1: compute.v1.JobAnnotations
	(*GenerationOptions)(nil),       // 2: compute.v1.GenerationOptions
	(*GenerateResponse)(nil),        // 3: compute.v1.GenerateResponse
	(*GenerateStreamResponse)(nil),  // 4: compute.v1.GenerateStreamResponse
	(*RoutingMetadata)(nil),         // 5: compute.v1.RoutingMetadata
	(*GenerationStats)(nil),         // 6: compute.v1.GenerationStats
	(*EmbedRequest)(nil),            // 7: compute.v1.EmbedRequest
	(*EmbedResponse)(nil),           // 8: compute.v1.EmbedResponse
	(*ListBackendsRequest)(nil),     // 9: compute.v1.ListBackendsRequest
	(*ListBackendsResponse)(nil),    // 10: compute.v1.ListBackendsResponse
	(*BackendInfo)(nil),             // 11: compute.v1.BackendInfo
	(*BackendStatus)(nil),           // 12: compute.v1.BackendStatus
	(*BackendCapabilities)(nil),     // 13: compute.v1.BackendCapabilities
	(*BackendMetrics)(nil),          // 14: compute.v1.BackendMetrics
	(*HealthCheckRequest)(nil),      // 15: compute.v1.HealthCheckRequest
	(*HealthCheckResponse)(nil),     // 16: compute.v1.HealthCheckResponse
	(*ExecutePipelineRequest)(nil),  // 17: compute.v1.ExecutePipelineRequest
	(*PipelineOptions)(nil),         // 18: compute.v1.PipelineOptions
	(*ExecutePipelineResponse)(nil), // 19: compute.v1.ExecutePipelineResponse
	(*StageResult)(nil),             // 20: compute.v1.StageResult
	(*StageMetadata)(nil),           // 21: compute.v1.StageMetadata
	(*PipelineStreamResponse)(nil),  // 22: compute.v1.PipelineStreamResponse
	nil,                             // 23: compute.v1.JobAnnotations.CustomEntry
	nil,                             // 24: compute.v1.HealthCheckResponse.BackendHealthEntry
	nil,                             // 25: compute.v1.ExecutePipelineRequest.InputEntry
	nil,                             // 26: compute.v1.ExecutePipelineResponse.FinalOutputEntry
}
var file_compute_proto_depIdxs = []int32{
	1,  // 0: compute.v1.GenerateRequest.annotations:type_name -> compute.v1.JobAnnotations
	2,  // 1: compute.v1.GenerateRequest.options:type_name -> compute.v1.GenerationOptions
	23, // 2: compute.v1.JobAnnotations.custom:type_name -> compute.v1.JobAnnotations.CustomEntry
	5,  // 3: compute.v1.GenerateResponse.routing:type_name -> compute.v1.RoutingMetadata
	6,  // 4: compute.v1.GenerateResponse.stats:type_name -> compute.v1.GenerationStats
	6,  // 5: compute.v1.GenerateStreamResponse.stats:type_name -> compute.v1.GenerationStats
	1,  // 6: compute.v1.EmbedRequest.annotations:type_name -> compute.v1.JobAnnotations
	5,  // 7: compute.v1.EmbedResponse.routing:type_name -> compute.v1.RoutingMetadata
	11, // 8: compute.v1.ListBackendsResponse.backends:type_name -> compute.v1.BackendInfo
	12, // 9: compute.v1.BackendInfo.status:type_name -> compute.v1.BackendStatus
	13, // 10: compute.v1.BackendInfo.capabilities:type_name -> compute.v1.BackendCapabilities
	14, // 11: compute.v1.BackendInfo.metrics:type_name -> compute.v1.BackendMetrics
	24, // 12: compute.v1.HealthCheckResponse.backend_health:type_name -> compute.v1.HealthCheckResponse.BackendHealthEntry
	25, // 13: compute.v1.ExecutePipelineRequest.input:type_name -> compute.v1.ExecutePipelineRequest.InputEntry
	18, // 14: compute.v1.ExecutePipelineRequest.options:type_name -> compute.v1.PipelineOptions
	1,  // 15: compute.v1.ExecutePipelineRequest.annotations:type_name -> compute.v1.JobAnnotations
	26, // 16: compute.v1.ExecutePipelineResponse.final_output:type_name -> compute.v1.ExecutePipelineResponse.FinalOutputEntry
	20, // 17: compute.v1.ExecutePipelineResponse.stage_results:type_name -> compute.v1.StageResult
	21, // 18: compute.v1.StageResult.metadata:type_name -> compute.v1.StageMetadata
	20, // 19: compute.v1.PipelineStreamResponse.stage_result:type_name -> compute.v1.StageResult
	19, // 20: compute.v1.PipelineStreamResponse.final_result:type_name -> compute.v1.ExecutePipelineResponse
	0,  // 21: compute.v1.ComputeService.Generate:input_type -> compute.v1.GenerateRequest
	0,  // 22: compute.v1.ComputeService.GenerateStream:input_type -> compute.v1.GenerateRequest
	7,  // 23: compute.v1.ComputeService.Embed:input_type -> compute.v1.EmbedRequest
	9,  // 24: compute.v1.ComputeService.ListBackends:input_type -> compute.v1.ListBackendsRequest
	15, // 25: compute.v1.ComputeService.HealthCheck:input_type -> compute.v1.HealthCheckRequest
	17, // 26: compute.v1.ComputeService.ExecutePipeline:input_type -> compute.v1.ExecutePipelineRequest
	17, // 27: compute.v1.ComputeService.ExecutePipelineStream:input_type -> compute.v1.ExecutePipelineRequest
	3,  // 28: compute.v1.ComputeService.Generate:output_type -> compute.v1.GenerateResponse
	4,  // 29: compute.v1.ComputeService.GenerateStream:output_type -> compute.v1.GenerateStreamResponse
	8,  // 30: compute.v1.ComputeService.Embed:output_type -> compute.v1.EmbedResponse
	10, // 31: compute.v1.ComputeService.ListBackends:output_type -> compute.v1.ListBackendsResponse
	16, // 32: compute.v1.ComputeService.HealthCheck:output_type -> compute.v1.HealthCheckResponse
	19, // 33: compute.v1.ComputeService.ExecutePipeline:output_type -> compute.v1.ExecutePipelineResponse
	22, // 34: compute.v1.ComputeService.ExecutePipelineStream:output_type -> compute.v1.PipelineStreamResponse
	28, // [28:35] is the sub-list for method output_type
	21, // [21:28] is the sub-list for method input_type
	21, // [21:21] is the sub-list for extension type_name
	21, // [21:21] is the sub-list for extension extendee
	0,  // [0:21] is the sub-list for field type_name
}

func init() { file_compute_proto_init() }
func file_compute_proto_init() {
	if File_compute_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_compute_proto_rawDesc), len(file_compute_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   27,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_compute_proto_goTypes,
		DependencyIndexes: file_compute_proto_depIdxs,
		MessageInfos:      file_compute_proto_msgTypes,
	}.Build()
	File_compute_proto = out.File
	file_compute_proto_goTypes = nil
	file_compute_proto_depIdxs = nil
}

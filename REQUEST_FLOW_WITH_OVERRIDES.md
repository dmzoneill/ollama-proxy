# Request Flow: User Flags vs. Efficiency Profile Overrides

## âœ… Yes, You Understand Correctly!

**User provides annotations â†’ Efficiency mode can override them**

## ðŸ“Š Complete Request Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLIENT (gRPC/HTTP Request)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  {                                                  â”‚
â”‚    "prompt": "Generate code",                       â”‚
â”‚    "model": "qwen2.5:0.5b",                        â”‚
â”‚    "annotations": {                                 â”‚
â”‚      "latency_critical": true,      â† USER REQUEST â”‚
â”‚      "target": "ollama-nvidia"      â† USER REQUEST â”‚
â”‚    }                                                â”‚
â”‚  }                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PROXY RECEIVES REQUEST                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CHECK EFFICIENCY MODE                              â”‚
â”‚  Current Mode: Quiet                                â”‚
â”‚  Profile Settings:                                  â”‚
â”‚    - max_power_watts: 15                           â”‚
â”‚    - max_fan_percent: 40                           â”‚
â”‚    - override_critical_flag: true                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  APPLY EFFICIENCY MODE OVERRIDES                    â”‚
â”‚                                                     â”‚
â”‚  User wants: NVIDIA (55W, fan could be 65%)        â”‚
â”‚  Mode limit: 15W max, 40% fan max                  â”‚
â”‚                                                     â”‚
â”‚  âŒ OVERRIDE: NVIDIA exceeds limits                â”‚
â”‚  âœ“  Use: NPU or Intel GPU instead                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CHECK THERMAL STATE                                â”‚
â”‚  NPU: 55Â°C, fan 0%     âœ“ OK                       â”‚
â”‚  Intel GPU: 62Â°C, 35%  âœ“ OK                       â”‚
â”‚  NVIDIA: 78Â°C, 65%     âŒ Blocked by mode          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FINAL ROUTING DECISION                             â”‚
â”‚  Selected: ollama-npu                               â”‚
â”‚  Reason: "Quiet mode, NVIDIA blocked (fan > 40%)"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RESPONSE TO CLIENT                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  {                                                  â”‚
â”‚    "response": "Generated text...",                 â”‚
â”‚    "backend_used": "ollama-npu",     â† ACTUAL      â”‚
â”‚    "user_requested": "ollama-nvidia", â† WHAT USER WANTED â”‚
â”‚    "override_applied": true,                        â”‚
â”‚    "override_reason": "Quiet mode fan limit (40%)", â”‚
â”‚    "routing": {                                     â”‚
â”‚      "reason": "Quiet mode active, NVIDIA fan too loud" â”‚
â”‚    }                                                â”‚
â”‚  }                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸŽ® Real Examples

### Example 1: Performance Mode (NO Override)

**Client sends:**
```json
{
  "prompt": "Write code",
  "annotations": {
    "latency_critical": true,
    "target": "ollama-nvidia"
  }
}
```

**Current mode:** `Performance`

**What happens:**
```
âœ“ User wants NVIDIA â†’ Performance mode respects this
âœ“ Check thermal: NVIDIA 65Â°C (OK)
âœ“ Route to: NVIDIA

Response:
{
  "backend_used": "ollama-nvidia",
  "override_applied": false,
  "routing": {
    "reason": "Performance mode, user request honored"
  }
}
```

**User got what they requested!**

---

### Example 2: Quiet Mode (OVERRIDE Applied)

**Client sends:**
```json
{
  "prompt": "Write code",
  "annotations": {
    "latency_critical": true,
    "target": "ollama-nvidia"
  }
}
```

**Current mode:** `Quiet`

**What happens:**
```
âœ— User wants NVIDIA
âœ“ Quiet mode check: NVIDIA fan at 65%
âœ— Quiet mode limit: 40% max fan
âœ— NVIDIA BLOCKED by profile
âœ“ Route to: NPU (0% fan)

Response:
{
  "backend_used": "ollama-npu",
  "user_requested": "ollama-nvidia",
  "override_applied": true,
  "override_reason": "Quiet mode, NVIDIA fan too loud (65% > 40%)",
  "routing": {
    "reason": "Quiet mode enforced, using silent backend"
  }
}
```

**User request OVERRIDDEN by Quiet mode!**

---

### Example 3: Efficiency Mode (OVERRIDE Applied)

**Client sends:**
```json
{
  "prompt": "Simple query",
  "annotations": {
    "latency_critical": true
  }
}
```

**Current mode:** `Efficiency`

**What happens:**
```
âœ— User says latency_critical
âœ“ Efficiency mode classifies: "Simple query"
âœ— Override critical flag (unjustified for simple query)
âœ“ Efficiency mode limit: 15W
âœ— NVIDIA uses 55W (exceeds limit)
âœ“ Route to: NPU (3W)

Response:
{
  "backend_used": "ollama-npu",
  "override_applied": true,
  "override_reason": "Efficiency mode power limit (15W), simple query",
  "annotations_respected": false,
  "routing": {
    "reason": "Simple query + efficiency mode, using NPU"
  }
}
```

**Both target and critical flag OVERRIDDEN!**

---

### Example 4: Auto Mode (Context-Dependent)

**Client sends:**
```json
{
  "prompt": "Generate analysis",
  "annotations": {
    "latency_critical": true,
    "target": "ollama-nvidia"
  }
}
```

**Current mode:** `Auto`
**Context:** Battery 15%, Time 11:30 PM

**What happens:**
```
âœ“ Auto mode detects:
  - Battery 15% (critical!)
  - Time 11:30 PM (quiet hours)
âœ“ Auto switches effective mode to: Ultra Efficiency

âœ— User wants NVIDIA
âœ— Ultra Efficiency mode: NPU ONLY
âœ“ Route to: NPU

Response:
{
  "backend_used": "ollama-npu",
  "user_requested": "ollama-nvidia",
  "override_applied": true,
  "override_reason": "Auto mode â†’ Ultra Efficiency (battery 15%)",
  "effective_mode": "UltraEfficiency",
  "routing": {
    "reason": "Battery critical, using power-saving mode"
  }
}
```

**OVERRIDDEN by Auto mode's context awareness!**

---

## ðŸ”‘ Key Points

### 1. **User ALWAYS Gets Transparency**

Every response includes:
```json
{
  "backend_used": "ollama-npu",           â† What actually happened
  "user_requested": "ollama-nvidia",      â† What user asked for
  "override_applied": true,               â† Was user overridden?
  "override_reason": "Quiet mode...",     â† Why?
  "annotations_respected": false          â† Were annotations honored?
}
```

### 2. **Override Hierarchy**

```
Priority 1: THERMAL SAFETY (never overridable)
  â”œâ”€ Temp > 85Â°C â†’ Backend excluded
  â”œâ”€ Throttling â†’ Backend excluded
  â””â”€ Hardware offline â†’ Backend excluded

Priority 2: EFFICIENCY MODE LIMITS
  â”œâ”€ Max power (e.g., 15W in Efficiency mode)
  â”œâ”€ Max fan speed (e.g., 40% in Quiet mode)
  â””â”€ Max temperature (per mode)

Priority 3: USER ANNOTATIONS
  â”œâ”€ latency_critical
  â”œâ”€ target=backend
  â””â”€ prefer_power_efficiency

Priority 4: DEFAULT ROUTING
  â””â”€ Smart complexity-based
```

### 3. **Control via Efficiency Mode**

```bash
# Want user annotations ALWAYS respected?
ai-efficiency set Performance
â†’ User flags control routing (except thermal safety)

# Want system to optimize?
ai-efficiency set Auto
â†’ System overrides based on context

# Want power savings?
ai-efficiency set Efficiency
â†’ System enforces 15W limit, overrides as needed

# Want silence?
ai-efficiency set Quiet
â†’ System enforces 40% fan limit, blocks loud backends
```

## ðŸ“ gRPC Request Example

### Client Code

```go
// Client sends request with annotations
resp, err := client.Generate(ctx, &pb.GenerateRequest{
    Prompt: "Generate code",
    Model:  "qwen2.5:0.5b",
    Annotations: &pb.JobAnnotations{
        LatencyCritical: true,           // User wants speed
        Target:         "ollama-nvidia",  // User wants NVIDIA
    },
})

// Check if overridden
if resp.Routing.Override_Applied {
    fmt.Printf("Request overridden: %s\n", resp.Routing.OverrideReason)
    fmt.Printf("Requested: %s, Got: %s\n",
        resp.UserRequested, resp.BackendUsed)
}
```

### Server Response (Quiet Mode Active)

```json
{
  "response": "Here's the generated code...",
  "backend_used": "ollama-npu",
  "user_requested": "ollama-nvidia",
  "override_applied": true,
  "override_reason": "Quiet mode, NVIDIA fan 65% > 40% limit",
  "routing": {
    "backend": "ollama-npu",
    "reason": "Quiet mode enforced, using silent NPU",
    "estimated_power_watts": 3.0,
    "estimated_latency_ms": 800,
    "alternatives": ["ollama-igpu"]
  },
  "stats": {
    "total_time_ms": 823,
    "tokens_generated": 150,
    "tokens_per_second": 18.2,
    "energy_wh": 0.0007
  },
  "annotations_respected": false
}
```

## ðŸŽ¯ Summary

**Yes, your understanding is EXACTLY correct:**

1. **Client sends:** Annotations/flags (latency_critical, target, etc.)
2. **Proxy checks:** Current efficiency mode profile
3. **Profile can override:** Based on mode settings
4. **Client always knows:** Response shows what was requested vs. what happened

**The efficiency mode is like a system-wide policy that can override individual request preferences.**

Think of it like:
- **Performance mode** = "Users are in charge"
- **Other modes** = "System optimizes, may override users"
- **Thermal safety** = "Always enforced, no exceptions"

You control this with:
- **GUI:** System menu â†’ AI Efficiency â†’ Select mode
- **CLI:** `ai-efficiency set <mode>`
- **Config:** `config/config.yaml` default mode
